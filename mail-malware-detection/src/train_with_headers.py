"""
Train a phishing detection pipeline with text + header features.
Uses ColumnTransformer to combine TF-IDF text with header-derived numeric features.
Saves pipeline to `--model-out`.
"""
import argparse
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import joblib
import numpy as np
from feature_extractor import HeaderFeatureExtractor


def load_data(path):
    df = pd.read_csv(path)
    df['text'] = (df['subject'].fillna('') + ' ' + df['body'].fillna('')).astype(str)
    return df


def build_pipeline():
    """
    Build a pipeline that:
    1. Extracts TF-IDF features from 'text' column (word + char n-grams)
    2. Extracts numeric header features (receiving_chain, esp, spf/dkim/dmarc)
    3. Combines them
    4. Trains LogisticRegression classifier
    """
    
    # Text feature extractor: word + char n-grams
    text_features = FeatureUnion([
        ('word', TfidfVectorizer(ngram_range=(1, 2), analyzer='word', max_features=10000)),
        ('char', TfidfVectorizer(ngram_range=(3, 5), analyzer='char_wb', max_features=5000)),
    ])
    
    # Header feature extractor
    header_extractor = HeaderFeatureExtractor()
    
    # Column transformer: apply different transformations to different columns
    preprocessor = ColumnTransformer([
        ('text', text_features, 'text'),
        ('headers', Pipeline([('extractor', header_extractor), ('scaler', StandardScaler())]), 
         ['receiving_chain', 'esp', 'spf_pass', 'dkim_pass', 'dmarc_pass', 'subject']),
    ], verbose_feature_names_out=False)
    
    pipe = Pipeline([
        ('preprocessor', preprocessor),
        ('clf', LogisticRegression(class_weight='balanced', solver='lbfgs', max_iter=1000))
    ])
    
    return pipe


def train(path, model_out):
    df = load_data(path)
    X = df[['text', 'receiving_chain', 'esp', 'spf_pass', 'dkim_pass', 'dmarc_pass', 'subject']]
    y = df['label']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"Training set size: {len(X_train)}, Test set size: {len(X_test)}")
    print(f"Class distribution in training: {y_train.value_counts().to_dict()}")
    
    pipeline = build_pipeline()
    pipeline.fit(X_train, y_train)

    preds = pipeline.predict(X_test)
    probs = pipeline.predict_proba(X_test)[:, 1]

    print('\n=== Classification Report ===')
    print(classification_report(y_test, preds, target_names=['Benign', 'Phishing']))
    
    print('\n=== Confusion Matrix ===')
    print(confusion_matrix(y_test, preds))
    
    try:
        auc = roc_auc_score(y_test, probs)
        print(f'\nROC-AUC Score: {auc:.4f}')
    except Exception as e:
        print(f'ROC-AUC calculation failed: {e}')

    joblib.dump(pipeline, model_out)
    print(f'\nâœ“ Saved pipeline to {model_out}')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', default='data/raw/phishing_dataset.csv')
    parser.add_argument('--model-out', default='models/phishing_pipeline.joblib')
    args = parser.parse_args()
    train(args.data, args.model_out)
